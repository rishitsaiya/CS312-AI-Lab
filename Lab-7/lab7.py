# -*- coding: utf-8 -*-
"""Lab-8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11VJMFA1dNnpqLqwR2VnjFNGHaQ2rFIbY
"""

import numpy as np
import operator

def left(action):
    if action == 0:
        return 2
    elif action == 1:
        return 3
    elif action == 2:
        return 1
    elif action == 3:
        return 0

def right(action):
    if action == 0:
        return 3
    elif action == 1:
        return 2
    elif action == 2:
        return 0
    elif action == 3:
        return 1

def transtition(i,j,action):
    if i==0 and j==4:
        new_i,new_j = i,j
        reward = 0
        prob = 0
        return [(new_i,new_j,prob,reward)]
    elif i==1 and j==4:
        new_i,new_j = i,j
        reward = 0
        prob = 0
        return [(new_i,new_j,prob,reward)]
    else:
        info = []
        for a in [action,left(action),right(action)]:
            new_i,new_j = i,j
            new_i = i-1 if a==0 and i-1 >=0 else i+1 if a==1 and i+1 <=3 else i
            new_j = j-1 if a==2 and j-1 >=0 else j+1 if a==3 and j+1 <= 4 else j
            if new_i==2 and new_j==1:
                new_i=i
                new_j=j
            prob = 0.8 if a==action else 0.1
            reward = grid[new_i][new_j]
            info.append((new_i,new_j,prob,reward))
        return info

def policy_itr(pi,gamma):
    V = np.zeros((4,5),dtype = float)
    flag = True
    itr = 0
    while(flag):
        delta = 0.11
        while(delta > 0.01):
            old_v = np.copy(V)
            for i in range(4):
                for j in range(5):
                    sum_over_action = 0
                    for action in range(4):
                        sum_over_state = 0.0
                        for next_i,next_j, prob, reward in transtition(i,j,action):
                            sum_over_state += prob*(reward+gamma*(old_v[next_i][next_j]))
                        sum_over_action += pi[i][j][action]*sum_over_state
                    V[i][j] = sum_over_action
                    temp = delta
            delta = np.max(np.absolute(old_v-V))
        #print(V)
        old_action = np.copy(pi)
        for i in range(4):
            for j in range(5):
                action_value = []
                for action in range(4):
                    sum_over_states = 0.0
                    for new_i,new_j, prob, reward in transtition(i,j,action):
                        sum_over_states += prob*(reward+gamma*V[new_i][new_j])
                    action_value.append(sum_over_states)
                max_value = max(action_value)
                count = 0
                for idx,value in enumerate(action_value):
                    if value == max_value:
                        count+=1
                        pi[i][j][idx] = 1.0
                    else:
                        pi[i][j][idx] = 0.0
                pi[i][j] = pi[i][j]/count
        if (old_action == pi).all():
            flag = False
        itr+=1
        #print(V,"\n",pi)
    return V,pi

def value_itr(pi,gamma):
    V = np.zeros((4,5),dtype = float)
    delta = 0.02
    while(delta>0.01):
        for i in range(4):
            for j in range(5):
                old_v = np.copy(V)
                action_value=[]
                for action in range(4):
                    sum_over_states = 0.0
                    for new_i,new_j, prob, reward in transtition(i,j,action):
                        sum_over_states += prob*(reward+gamma*V[new_i][new_j])
                    action_value.append(sum_over_states)
                V[i][j] = max(action_value)
        delta = np.max(np.absolute(old_v-V))
    for i in range(4):
        for j in range(5):
            action_value = []
            for action in range(4):
                sum_over_states = 0.0
                for new_i,new_j, prob, reward in transtition(i,j,action):
                    sum_over_states += prob*(reward+gamma*V[new_i][new_j])
                action_value.append(sum_over_states)
            max_value = max(action_value)
            count = 0
            for idx,value in enumerate(action_value):
                if value == max_value:
                    count+=1
                    pi[i][j][idx] = 1.0
                else:
                    pi[i][j][idx] = 0.0
            pi[i][j] = pi[i][j]/count
    return V,pi

grid = np.array([[-1,-1,-1,-1,+10],
        [-1,-1,-1,-1,-200],
        [-1,-1,-1,-1,-1],
        [-1,-1,-1,-1,-1]])

pi = np.full((4,5,4),0.25) # 0: North/UP , 1: south/DOWN, 2: west/LEFT, 3: east/RIGHT
print(transtition(3,1,1))
V,pi=policy_itr(pi,0.9)
print(V)
print(pi)
pi = np.full((4,5,4),0.25) # 0: UP , 1: DOWN, 2: LEFT, 3: RIGHT
V,pi = value_itr(pi,0)
print(V)
print(pi)

